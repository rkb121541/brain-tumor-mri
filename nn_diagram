digraph {
	graph [size="16.349999999999998,16.349999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2515199128864 [label="
 ()" fillcolor=darkolivegreen1]
	2515343043568 [label="MeanBackward0
----------------------
self_sym_numel:      1
self_sym_sizes: (1, 1)"]
	2515344058992 -> 2515343043568
	2515344058992 -> 2515344302208 [dir=none]
	2515344302208 [label="result
 (1, 1)" fillcolor=orange]
	2515344058992 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	2515343858016 -> 2515344058992
	2515343858016 -> 2515344305328 [dir=none]
	2515344305328 [label="mat1
 (1, 84)" fillcolor=orange]
	2515343858016 -> 2515344296448 [dir=none]
	2515344296448 [label="mat2
 (84, 1)" fillcolor=orange]
	2515343858016 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (1, 84)
mat1_sym_strides:        (84, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (84, 1)
mat2_sym_strides:        (1, 84)"]
	2515172581600 -> 2515343858016
	2515344310912 [label="fc_model.4.bias
 (1)" fillcolor=lightblue]
	2515344310912 -> 2515172581600
	2515172581600 [label=AccumulateGrad]
	2517765837520 -> 2515343858016
	2517765837520 -> 2515344306688 [dir=none]
	2515344306688 [label="result
 (1, 84)" fillcolor=orange]
	2517765837520 [label="TanhBackward0
----------------------
result: [saved tensor]"]
	2515191414208 -> 2517765837520
	2515191414208 -> 2515344297088 [dir=none]
	2515344297088 [label="mat1
 (1, 120)" fillcolor=orange]
	2515191414208 -> 2515344305808 [dir=none]
	2515344305808 [label="mat2
 (120, 84)" fillcolor=orange]
	2515191414208 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 120)
mat1_sym_strides:       (120, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (120, 84)
mat2_sym_strides:       (1, 120)"]
	2517807384272 -> 2515191414208
	2515344319712 [label="fc_model.2.bias
 (84)" fillcolor=lightblue]
	2515344319712 -> 2517807384272
	2517807384272 [label=AccumulateGrad]
	2517766047152 -> 2515191414208
	2517766047152 -> 2517813288048 [dir=none]
	2517813288048 [label="result
 (1, 120)" fillcolor=orange]
	2517766047152 [label="TanhBackward0
----------------------
result: [saved tensor]"]
	2517766049264 -> 2517766047152
	2517766049264 -> 2515344323392 [dir=none]
	2515344323392 [label="mat1
 (1, 256)" fillcolor=orange]
	2517766049264 -> 2517813289888 [dir=none]
	2517813289888 [label="mat2
 (256, 120)" fillcolor=orange]
	2517766049264 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 120)
mat2_sym_strides:       (1, 256)"]
	2517819912304 -> 2517766049264
	2515344324192 [label="fc_model.0.bias
 (120)" fillcolor=lightblue]
	2515344324192 -> 2517819912304
	2517819912304 [label=AccumulateGrad]
	2517819903616 -> 2517766049264
	2517819903616 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 16, 4, 4)"]
	2515343454800 -> 2517819903616
	2515343454800 -> 2515344297328 [dir=none]
	2515344297328 [label="self
 (1, 16, 21, 21)" fillcolor=orange]
	2515343454800 [label="AvgPool2DBackward0
---------------------------------
ceil_mode        :          False
count_include_pad:           True
divisor_override :           None
kernel_size      :         (2, 2)
padding          :         (0, 0)
self             : [saved tensor]
stride           :         (5, 5)"]
	2517897528608 -> 2515343454800
	2517897528608 -> 2515344315632 [dir=none]
	2515344315632 [label="result
 (1, 16, 21, 21)" fillcolor=orange]
	2517897528608 [label="TanhBackward0
----------------------
result: [saved tensor]"]
	2517810977744 -> 2517897528608
	2517810977744 -> 2515344316112 [dir=none]
	2515344316112 [label="input
 (1, 6, 25, 25)" fillcolor=orange]
	2517810977744 -> 2515344314352 [dir=none]
	2515344314352 [label="weight
 (16, 6, 5, 5)" fillcolor=orange]
	2517810977744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (16,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2515344610096 -> 2517810977744
	2515344610096 -> 2515344319952 [dir=none]
	2515344319952 [label="self
 (1, 6, 124, 124)" fillcolor=orange]
	2515344610096 [label="AvgPool2DBackward0
---------------------------------
ceil_mode        :          False
count_include_pad:           True
divisor_override :           None
kernel_size      :         (2, 2)
padding          :         (0, 0)
self             : [saved tensor]
stride           :         (5, 5)"]
	2515344618688 -> 2515344610096
	2515344618688 -> 2515344519280 [dir=none]
	2515344519280 [label="result
 (1, 6, 124, 124)" fillcolor=orange]
	2515344618688 [label="TanhBackward0
----------------------
result: [saved tensor]"]
	2515344617728 -> 2515344618688
	2515344617728 -> 2517617596992 [dir=none]
	2517617596992 [label="input
 (1, 3, 128, 128)" fillcolor=orange]
	2515344617728 -> 2517487826208 [dir=none]
	2517487826208 [label="weight
 (6, 3, 5, 5)" fillcolor=orange]
	2515344617728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (6,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2515344607264 -> 2515344617728
	2517487826208 [label="cnn_model.0.weight
 (6, 3, 5, 5)" fillcolor=lightblue]
	2517487826208 -> 2515344607264
	2515344607264 [label=AccumulateGrad]
	2515344616816 -> 2515344617728
	2517618400368 [label="cnn_model.0.bias
 (6)" fillcolor=lightblue]
	2517618400368 -> 2515344616816
	2515344616816 [label=AccumulateGrad]
	2515344609520 -> 2517810977744
	2515344314352 [label="cnn_model.3.weight
 (16, 6, 5, 5)" fillcolor=lightblue]
	2515344314352 -> 2515344609520
	2515344609520 [label=AccumulateGrad]
	2515344621520 -> 2517810977744
	2515344325872 [label="cnn_model.3.bias
 (16)" fillcolor=lightblue]
	2515344325872 -> 2515344621520
	2515344621520 [label=AccumulateGrad]
	2515343454560 -> 2517766049264
	2515343454560 [label=TBackward0]
	2515344050976 -> 2515343454560
	2515344312192 [label="fc_model.0.weight
 (120, 256)" fillcolor=lightblue]
	2515344312192 -> 2515344050976
	2515344050976 [label=AccumulateGrad]
	2517766050656 -> 2515191414208
	2517766050656 [label=TBackward0]
	2515344056304 -> 2517766050656
	2515199437120 [label="fc_model.2.weight
 (84, 120)" fillcolor=lightblue]
	2515199437120 -> 2515344056304
	2515344056304 [label=AccumulateGrad]
	2517875311184 -> 2515343858016
	2517875311184 [label=TBackward0]
	2517808123232 -> 2517875311184
	2515344316272 [label="fc_model.4.weight
 (1, 84)" fillcolor=lightblue]
	2515344316272 -> 2517808123232
	2517808123232 [label=AccumulateGrad]
	2515343043568 -> 2515199128864
}
